{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMl0SbcXlyLy91FuFxyPBp0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nijatmaharramov/Computer-Vision-Projects/blob/main/Fruit_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fruits and Vegetables Image Recognition Dataset"
      ],
      "metadata": {
        "id": "JM6k-_D4TOQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libraries and creating paths to datasets#"
      ],
      "metadata": {
        "id": "_DP713u1BjZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import warnings"
      ],
      "metadata": {
        "id": "eVTHna2ztlYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "7Ed4JTRAceBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "XX5VaiKvwDiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "vxJFM5VPtlxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "8V9zJ9H-wJq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d kritikseth/fruit-and-vegetable-image-recognition"
      ],
      "metadata": {
        "id": "_qT60TyjwVKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip fruit-and-vegetable-image-recognition.zip"
      ],
      "metadata": {
        "id": "EtaY3UiGwYDt",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dirpath, dirnames, filenames, in os.walk('/content/train'):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "LH-c5mTnwxUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_data_path = '/content/train'\n",
        "\n",
        "\n",
        "train_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_data_path,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    interpolation='nearest',\n",
        "    batch_size=32)\n",
        "\n",
        "class_names = train_data.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "tO-6oINKw_aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_path = '/content/test'\n",
        "\n",
        "test_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_data_path,\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'categorical',\n",
        "    image_size=(224,224),\n",
        "    interpolation='nearest',\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "wK40XqLRxnGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data_path = '/content/validation'\n",
        "\n",
        "validation_data = tf.keras.utils.image_dataset_from_directory(\n",
        "    validation_data_path,\n",
        "    labels = 'inferred',\n",
        "    label_mode = 'categorical',\n",
        "    image_size=(224,224),\n",
        "    interpolation='nearest',\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "id": "XkDpdz5PynxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 15))\n",
        "for images, labels in train_data.take(1):\n",
        "  for i in range(12):\n",
        "    ax = plt.subplot(6, 6, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i].numpy().argmax()])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "fljG-da6yysJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Our first model"
      ],
      "metadata": {
        "id": "aSHNQ2kjBzPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape = (224,224,3)),\n",
        "    tf.keras.layers.Rescaling(1 / 255.),\n",
        "    tf.keras.layers.Conv2D(64, kernel_size = 7, padding='same', activation='relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Conv2D(128, kernel_size = 3, padding='same', activation='relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Conv2D(128, kernel_size = 3, padding='same', activation='relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Conv2D(256, kernel_size = 3, padding='same', activation='relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Conv2D(256, kernel_size = 3, padding='same', activation='relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation='relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(len(class_names), activation='softmax', kernel_initializer='glorot_normal')\n",
        "    ])"
      ],
      "metadata": {
        "id": "ofTO4ABK0XjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy', 'f1_score'])\n",
        "\n",
        "model.fit(train_data, validation_data=validation_data, epochs=5 )"
      ],
      "metadata": {
        "id": "7-6OLr423QsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Pre-trained Model"
      ],
      "metadata": {
        "id": "5fs0OdG8B8Yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape = (224, 224, 3))\n",
        "\n",
        "x = tf.keras.applications.resnet50.preprocess_input(inputs)\n",
        "\n"
      ],
      "metadata": {
        "id": "q8B987w1UHLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_model = tf.keras.applications.ResNet50(\n",
        "    input_shape=(224,224,3),\n",
        "    input_tensor=x,\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    pooling='avg'\n",
        ")"
      ],
      "metadata": {
        "id": "OxEkv9jtTD1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "    print(layer.name)"
      ],
      "metadata": {
        "id": "AzawcURlT6T7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_model.trainable = False"
      ],
      "metadata": {
        "id": "FK14-KbeVlcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.Sequential([\n",
        "    pre_trained_model,\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dense(64, activation='relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dense(len(class_names), activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "BM0SkEh4V7x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model2, show_shapes=True, show_layer_names=False, dpi=100)\n"
      ],
      "metadata": {
        "id": "ViuzEM6VXQfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(loss='categorical_crossentropy',\n",
        "               optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "               metrics=['accuracy', 'f1_score'])"
      ],
      "metadata": {
        "id": "_odKbDYnXdLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"fruit_detector.keras\", save_best_only = True)\n",
        "\n",
        "early_stp = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "# ReduceLROnPlateau - it reduces lr 0.5 times if there is no positive progress on val_loss for 3 epochs\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)"
      ],
      "metadata": {
        "id": "2B8se2MPX70U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model2.fit(train_data, validation_data=validation_data, epochs=10, callbacks=[checkpoint_cb, early_stp])"
      ],
      "metadata": {
        "id": "_b8eKVlubkvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictive system"
      ],
      "metadata": {
        "id": "BYGw2v9pCFr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "def plot_and_pred(model, image_path):\n",
        "    plt.figure(figsize = (12,12))\n",
        "    image = mpimg.imread(image_path)\n",
        "    image = tf.image.resize(image, (224,224))\n",
        "    pred_probs = model.predict(np.expand_dims(image, axis=0))\n",
        "    pred = class_names[np.argmax(pred_probs)]\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image / 255.)\n",
        "    plt.title(pred, color = 'green')\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.bar(class_names, pred_probs[0])\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel('Probability')\n",
        "    plt.xticks(rotation=90)\n"
      ],
      "metadata": {
        "id": "K-KZbHQ8edeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_and_pred(model2, '/content/red-apple-freshleaf-dubai-uae-img01.jpg')"
      ],
      "metadata": {
        "id": "wf5XKhlEiTBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_and_pred(model2, '/content/Watermelon-cuts-24-1.jpg')"
      ],
      "metadata": {
        "id": "VJx-VA0JrWYM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}